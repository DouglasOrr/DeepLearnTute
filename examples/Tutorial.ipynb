{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import useful packages\n",
    "\n",
    "%matplotlib inline\n",
    "import dlt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import chainer as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment with softmax cross entropy\n",
    "\n",
    "def test_softmax_cross_entropy(scores, targets):\n",
    "    '''Find the softmax cross entropy between a constant set of scores & a sequence of targets.\n",
    "    scores -- list of N scores, e.g. [0.0, 1.5, -0.7]\n",
    "    targets -- list of targets, e.g. [1, 0, 0, 2, 0]\n",
    "    '''\n",
    "    s = C.Variable(np.tile(np.array(scores, dtype=np.float32), (len(targets), 1)))\n",
    "    t = C.Variable(np.array(targets, dtype=np.int32))\n",
    "    return float(C.functions.softmax_cross_entropy(s, t).data)\n",
    "\n",
    "print(test_softmax_cross_entropy(scores=[0.0, -1.0], targets=[1]))\n",
    "print(test_softmax_cross_entropy(scores=[0.0, -1.0], targets=[0, 0, 1]))\n",
    "print(test_softmax_cross_entropy(scores=[0.0, -1.0], targets=[1, 1, 0]))\n",
    "\n",
    "# TODO - add your softmax_cross_entropy experiments..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load up & show the data\n",
    "\n",
    "train = dlt.load_hdf5('/data/uji/train.hdf')\n",
    "valid = dlt.load_hdf5('/data/uji/valid.hdf')\n",
    "print(\"  Training: %s\" % train)\n",
    "print(\"Validation: %s\" % valid)\n",
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO - select data, define & train a model\n",
    "\n",
    "print(\"vocab:\", train.vocab)\n",
    "print(\"--- first training example: ---\")\n",
    "print(\"target:\", train.y[0])\n",
    "print(\"character:\", train.vocab[train.y[0]])\n",
    "print(\"input:\", train.x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# (Optional) log plotting helper example\n",
    "\n",
    "log = dlt.Log()\n",
    "for i in range(20):\n",
    "    log.add('loss', 'train', 1 / (1 + i))\n",
    "    log.add('accuracy', 'train', 2 * i)\n",
    "    log.add('loss', 'valid', 2 / (1 + i))\n",
    "    log.add('accuracy', 'valid', i)\n",
    "log.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# (Optional) demo - try your classifier \n",
    "\n",
    "def classify(img):\n",
    "    # Hint - if you need a batch dimension, try: img.reshape(1, -1)\n",
    "    print(\"TODO - classify img, shape %s\" % img.shape)\n",
    "    scores = np.random.randn(1, len(train.vocab))  # TODO - replace with real scores\n",
    "    return train.vocab[np.argmax(scores)]\n",
    "\n",
    "# quick check\n",
    "assert classify(valid.x[0, :]) in train.vocab\n",
    "\n",
    "dlt.CustomInput(classify)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
